{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70e1ad4-9007-4a75-9b84-33a927bfa3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working folder: D:\\Global Warming\n",
      "Saved sea_level_clean.csv (rows): 144\n",
      "CSIRO sea level delta (max-min): 9.68503936\n",
      "Processed 2000000 rows...\n",
      "Processed 4000000 rows...\n",
      "Processed 6000000 rows...\n",
      "Processed 8000000 rows...\n",
      "Saved temperature_by_year.csv (years): 267\n",
      "Using CO2 file: owid-co2-data.csv\n",
      "Saved co2_clean.csv (rows): 50191 countries: 255\n",
      "Found explicit 'World' rows in CO2 data. Using them for global totals.\n",
      "Saved co2_world_by_year.csv (years): 274 | Assumed original 'co2' = million tonnes; produced co2_billion = co2 / 1000\n",
      "Latest year in world table: 2023\n",
      "Latest world row sample -> co2 (raw): 37791.57 co2_billion: 37.79157 population_billion: 8.091734935\n",
      "\n",
      "ALL DONE. Files written:\n",
      " - sea_level_clean.csv\n",
      " - temperature_by_year.csv\n",
      " - co2_clean.csv\n",
      " - co2_world_by_year.csv\n"
     ]
    }
   ],
   "source": [
    "# Put this cell in a Jupyter notebook opened in your project folder (e.g. D:\\GlobalWarmingProject)\n",
    "# It will read the three raw files, clean them, and write 4 PowerBI-ready CSVs.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "DATA_DIR = r\"D:\\Global Warming\"   # <-- change only if your folder is different\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "print(\"Working folder:\", os.getcwd())\n",
    "\n",
    "# ---------------------------\n",
    "# 1) SEA LEVEL\n",
    "# ---------------------------\n",
    "sea_fname = \"epa-sea-level.csv\"\n",
    "if not os.path.exists(sea_fname):\n",
    "    raise FileNotFoundError(f\"{sea_fname} not found in {DATA_DIR}\")\n",
    "\n",
    "sea = pd.read_csv(sea_fname)\n",
    "# keep only Year and main columns, robust renaming\n",
    "expected_cols = [\"Year\", \"CSIRO Adjusted Sea Level\", \"NOAA Adjusted Sea Level\"]\n",
    "found = [c for c in expected_cols if c in sea.columns]\n",
    "if len(found) < 2:\n",
    "    print(\"Warning: unexpected sea-level columns; saving whatever is available.\")\n",
    "sea = sea[[c for c in expected_cols if c in sea.columns]]\n",
    "sea = sea.rename(columns={\n",
    "    \"CSIRO Adjusted Sea Level\": \"CSIRO_sea_level\",\n",
    "    \"NOAA Adjusted Sea Level\": \"NOAA_sea_level\"\n",
    "})\n",
    "# Ensure numeric and drop invalid years\n",
    "sea[\"Year\"] = pd.to_numeric(sea[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "for col in [\"CSIRO_sea_level\", \"NOAA_sea_level\"]:\n",
    "    if col in sea.columns:\n",
    "        sea[col] = pd.to_numeric(sea[col], errors=\"coerce\")\n",
    "sea = sea.dropna(subset=[\"Year\"])\n",
    "sea.to_csv(\"sea_level_clean.csv\", index=False)\n",
    "print(\"Saved sea_level_clean.csv (rows):\", len(sea))\n",
    "\n",
    "# quick check of sea-level rise (print)\n",
    "if \"CSIRO_sea_level\" in sea.columns:\n",
    "    try:\n",
    "        csiro_rise = sea[\"CSIRO_sea_level\"].max() - sea[\"CSIRO_sea_level\"].min()\n",
    "        print(\"CSIRO sea level delta (max-min):\", csiro_rise)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------------------\n",
    "# 2) TEMPERATURE (large file => chunked)\n",
    "# ---------------------------\n",
    "temp_fname = \"GlobalLandTemperaturesByCity.csv\"\n",
    "if not os.path.exists(temp_fname):\n",
    "    raise FileNotFoundError(f\"{temp_fname} not found in {DATA_DIR}\")\n",
    "\n",
    "# We'll compute year-wise sum and count to get accurate averages without loading all rows at once\n",
    "chunksize = 500_000\n",
    "sum_by_year = {}\n",
    "count_by_year = {}\n",
    "\n",
    "reader = pd.read_csv(temp_fname, usecols=[\"dt\", \"AverageTemperature\"], parse_dates=[\"dt\"], chunksize=chunksize)\n",
    "for i, chunk in enumerate(reader):\n",
    "    chunk[\"Year\"] = chunk[\"dt\"].dt.year\n",
    "    # remove NA temps\n",
    "    chunk = chunk.dropna(subset=[\"AverageTemperature\", \"Year\"])\n",
    "    g = chunk.groupby(\"Year\")[\"AverageTemperature\"].agg([\"sum\", \"count\"])\n",
    "    for year, row in g.iterrows():\n",
    "        y = int(year)\n",
    "        sum_by_year[y] = sum_by_year.get(y, 0.0) + float(row[\"sum\"])\n",
    "        count_by_year[y] = count_by_year.get(y, 0) + int(row[\"count\"])\n",
    "    if (i+1) % 4 == 0:\n",
    "        print(f\"Processed { (i+1)*chunksize } rows...\")\n",
    "\n",
    "# finalize temperature by year\n",
    "years = sorted(sum_by_year.keys())\n",
    "temp_rows = []\n",
    "for y in years:\n",
    "    s = sum_by_year[y]\n",
    "    c = count_by_year[y]\n",
    "    temp_rows.append({\"Year\": int(y), \"AvgTemperature\": (s / c) if c>0 else np.nan, \"ObsCount\": c})\n",
    "temp_df = pd.DataFrame(temp_rows)\n",
    "temp_df = temp_df.sort_values(\"Year\").reset_index(drop=True)\n",
    "temp_df.to_csv(\"temperature_by_year.csv\", index=False)\n",
    "print(\"Saved temperature_by_year.csv (years):\", len(temp_df))\n",
    "\n",
    "# ---------------------------\n",
    "# 3) CO2 (OWID) - robust cleaning\n",
    "# ---------------------------\n",
    "co2_fname_candidates = [\"owid-co2-data.csv\", \"owid-co2-data-full.csv\", \"owid-co2-data (1).csv\"]\n",
    "co2_fname = None\n",
    "for f in co2_fname_candidates:\n",
    "    if os.path.exists(f):\n",
    "        co2_fname = f\n",
    "        break\n",
    "if co2_fname is None:\n",
    "    # fallback: check any file that starts with owid-co2\n",
    "    for f in os.listdir(DATA_DIR):\n",
    "        if f.lower().startswith(\"owid-co2\"):\n",
    "            co2_fname = f\n",
    "            break\n",
    "if co2_fname is None:\n",
    "    raise FileNotFoundError(\"OWID CO2 data file not found. Place 'owid-co2-data.csv' in the folder.\")\n",
    "print(\"Using CO2 file:\", co2_fname)\n",
    "\n",
    "co2 = pd.read_csv(co2_fname)\n",
    "# ensure we have these columns; if not present, try to adapt\n",
    "keep_cols = []\n",
    "for c in [\"country\",\"iso_code\",\"year\",\"co2\",\"co2_per_capita\",\"gdp\",\"population\"]:\n",
    "    if c in co2.columns:\n",
    "        keep_cols.append(c)\n",
    "co2 = co2[keep_cols].copy()\n",
    "\n",
    "# convert types\n",
    "co2[\"year\"] = pd.to_numeric(co2[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "for col in [\"co2\",\"co2_per_capita\",\"gdp\",\"population\"]:\n",
    "    if col in co2.columns:\n",
    "        co2[col] = pd.to_numeric(co2[col], errors=\"coerce\")\n",
    "\n",
    "# Keep only rows with a valid year\n",
    "co2 = co2.dropna(subset=[\"year\"])\n",
    "co2 = co2.sort_values([\"country\",\"year\"]).reset_index(drop=True)\n",
    "\n",
    "# Save cleaned country-year file\n",
    "co2.to_csv(\"co2_clean.csv\", index=False)\n",
    "print(\"Saved co2_clean.csv (rows):\", len(co2), \"countries:\", co2['country'].nunique())\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Create a WORLD (global) by-year table (co2_world_by_year.csv)\n",
    "#    - If 'World' row exists, use it.\n",
    "#    - Else compute global totals by summing only rows with a valid iso_code (to avoid double-counting region-aggregates).\n",
    "# ---------------------------\n",
    "world_by_year = None\n",
    "if \"country\" in co2.columns and \"iso_code\" in co2.columns:\n",
    "    # prefer explicit 'World' row if present\n",
    "    if (co2['country'].astype(str).str.lower() == \"world\").any():\n",
    "        world_by_year = co2[co2['country'].str.lower() == \"world\"].copy()\n",
    "        world_by_year = world_by_year[[\"year\",\"co2\",\"population\"]]\n",
    "        world_by_year = world_by_year.rename(columns={\"year\":\"Year\",\"co2\":\"co2\",\"population\":\"population\"})\n",
    "        print(\"Found explicit 'World' rows in CO2 data. Using them for global totals.\")\n",
    "    else:\n",
    "        # sum only rows with non-null iso_code (these are country rows, not aggregates)\n",
    "        countries = co2[co2[\"iso_code\"].notna() & (co2[\"iso_code\"]!=\"\")].copy()\n",
    "        if len(countries)==0:\n",
    "            # fallback: sum across all rows (last resort)\n",
    "            print(\"No iso_code values found; summing across all rows as fallback.\")\n",
    "            aggregated = co2.groupby(\"year\").agg({\"co2\":\"sum\",\"population\":\"sum\"}).reset_index()\n",
    "        else:\n",
    "            aggregated = countries.groupby(\"year\").agg({\"co2\":\"sum\",\"population\":\"sum\"}).reset_index()\n",
    "        aggregated = aggregated.rename(columns={\"year\":\"Year\"})\n",
    "        world_by_year = aggregated[[\"Year\",\"co2\",\"population\"]].copy()\n",
    "        print(\"Computed global totals by summing country iso_code rows.\")\n",
    "else:\n",
    "    # co2 file missing iso_code; sum across all rows (best effort)\n",
    "    aggregated = co2.groupby(\"year\").agg({\"co2\":\"sum\",\"population\":\"sum\"}).reset_index().rename(columns={\"year\":\"Year\"})\n",
    "    world_by_year = aggregated[[\"Year\",\"co2\",\"population\"]].copy()\n",
    "    print(\"CO2 file had no iso_code column; used sum across all rows.\")\n",
    "\n",
    "# Add helper columns: co2_billion (assume OWID 'co2' is in million tonnes)\n",
    "# detect scale: check recent-year value\n",
    "if \"co2\" in world_by_year.columns:\n",
    "    latest_year = int(world_by_year[\"Year\"].max())\n",
    "    sample = world_by_year.loc[world_by_year[\"Year\"]==latest_year,\"co2\"].iloc[0]\n",
    "    # if sample is large (>1000) assume it's Mt (million tonnes) -> convert to billion by dividing 1000\n",
    "    if pd.notna(sample) and sample > 1000:\n",
    "        world_by_year[\"co2_billion\"] = world_by_year[\"co2\"] / 1000.0\n",
    "        scale_note = \"Assumed original 'co2' = million tonnes; produced co2_billion = co2 / 1000\"\n",
    "    else:\n",
    "        world_by_year[\"co2_billion\"] = world_by_year[\"co2\"]\n",
    "        scale_note = \"Assumed original 'co2' already in billions; co2_billion = co2\"\n",
    "    world_by_year[\"population_billion\"] = world_by_year[\"population\"] / 1_000_000_000.0\n",
    "else:\n",
    "    world_by_year[\"co2_billion\"] = np.nan\n",
    "    world_by_year[\"population_billion\"] = np.nan\n",
    "    scale_note = \"No co2 column found\"\n",
    "\n",
    "world_by_year.to_csv(\"co2_world_by_year.csv\", index=False)\n",
    "print(\"Saved co2_world_by_year.csv (years):\", len(world_by_year), \"|\", scale_note)\n",
    "\n",
    "# Print sample of latest year values\n",
    "ly = world_by_year[\"Year\"].max()\n",
    "row = world_by_year[world_by_year[\"Year\"]==ly].iloc[0]\n",
    "print(f\"Latest year in world table: {ly}\")\n",
    "print(\"Latest world row sample -> co2 (raw):\", row.get(\"co2\"), \"co2_billion:\", row.get(\"co2_billion\"), \"population_billion:\", row.get(\"population_billion\"))\n",
    "\n",
    "print(\"\\nALL DONE. Files written:\")\n",
    "print(\" - sea_level_clean.csv\")\n",
    "print(\" - temperature_by_year.csv\")\n",
    "print(\" - co2_clean.csv\")\n",
    "print(\" - co2_world_by_year.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334cb79-da2c-4e41-a980-cb5036d631d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
